{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b1173e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def extract_cifar_data(url, filename=\"cifar.tar.gz\"):\n",
    "    \"\"\"A function for extracting the CIFAR-100 dataset and storing it as a gzipped file.\n",
    "\n",
    "    Arguments:\n",
    "    url      -- the URL where the dataset is hosted\n",
    "    filename -- the full path where the dataset will be written\n",
    "    \"\"\"\n",
    "    # Make an HTTP GET request to fetch the dataset\n",
    "    r = requests.get(url, stream=True)\n",
    "    \n",
    "    # Open the file in binary write mode and save the content\n",
    "    with open(filename, \"wb\") as file:\n",
    "        for chunk in r.iter_content(chunk_size=1024):  # Download in chunks to avoid memory overload\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "    print(f\"Dataset downloaded and saved as {filename}\")\n",
    "\n",
    "# Run the function to download the CIFAR-100 dataset\n",
    "extract_cifar_data(\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4468a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def extract_cifar_data(url, filename=\"cifar.tar.gz\"):\n",
    "    \"\"\"A function for extracting the CIFAR-100 dataset and storing it as a gzipped file\n",
    "    \n",
    "    Arguments:\n",
    "    url      -- the URL where the dataset is hosted\n",
    "    filename -- the full path where the dataset will be written\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Todo: request the data from the data url\n",
    "    # Hint: use `requests.get` method\n",
    "    r = requests.get(url)\n",
    "    with open(filename, \"wb\") as file_context:\n",
    "        file_context.write(r.content)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bca63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_cifar_data(\"https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\")     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55322ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"cifar.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfc4984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./cifar-100-python/meta\", \"rb\") as f:\n",
    "    dataset_meta = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/test\", \"rb\") as f:\n",
    "    dataset_test = pickle.load(f, encoding='bytes')\n",
    "\n",
    "with open(\"./cifar-100-python/train\", \"rb\") as f:\n",
    "    dataset_train = pickle.load(f, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d25b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb2a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94818821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Each 1024 in a row is a channel (red, green, then blue)\n",
    "row = dataset_train[b'data'][0]\n",
    "red, green, blue = row[0:1024], row[1024:2048], row[2048:]\n",
    "\n",
    "# Each 32 items in the channel are a row in the 32x32 image\n",
    "red = red.reshape(32,32)\n",
    "green = green.reshape(32,32)\n",
    "blue = blue.reshape(32,32)\n",
    "\n",
    "# Combine the channels into a 32x32x3 image!\n",
    "combined = np.dstack((red,green,blue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All in one:\n",
    "test_image = np.dstack((\n",
    "    row[0:1024].reshape(32,32),\n",
    "    row[1024:2048].reshape(32,32),\n",
    "    row[2048:].reshape(32,32)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bb6314",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test_image);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train[b'fine_labels'][0]\n",
    "print(dataset_meta[b'fine_label_names'][19])\n",
    "n = 0\n",
    "print(dataset_meta[b'fine_label_names'][dataset_train[b'fine_labels'][n]])\n",
    "print(dataset_train[b'filenames'][0])\n",
    "plt.imsave(\"file.png\", test_image)\n",
    "import pandas as pd\n",
    "\n",
    "# Todo: Filter the dataset_train and dataset_meta objects to find the label numbers for Bicycle and Motorcycles\n",
    "\n",
    "bicycle_index = dataset_meta[b'fine_label_names'].index(b'bicycle')\n",
    "motocycle_index = dataset_meta[b'fine_label_names'].index(b'motorcycle')\n",
    "\n",
    "print (bicycle_index)\n",
    "print(motocycle_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa791a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the dataframe\n",
    "df_train = pd.DataFrame({\n",
    "    \"filenames\": dataset_train[b'filenames'],\n",
    "    \"labels\": dataset_train[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_train[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_train where label is not 8 or 48\n",
    "df_train = df_train.loc[df_train[\"labels\"].isin([8,48])]\n",
    "                                        #TODO: Fill in\n",
    "\n",
    "# Decode df_train.filenames so they are regular strings\n",
    "df_train[\"filenames\"] = df_train[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")\n",
    "\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"filenames\": dataset_test[b'filenames'],\n",
    "    \"labels\": dataset_test[b'fine_labels'],\n",
    "    \"row\": range(len(dataset_test[b'filenames']))\n",
    "})\n",
    "\n",
    "# Drop all rows from df_test where label is not 8 or 48\n",
    "df_test = df_test.loc[df_test[\"labels\"].isin([8,48])]\n",
    "# Decode df_test.filenames so they are regular strings\n",
    "df_test[\"filenames\"] = df_test[\"filenames\"].apply(\n",
    "    lambda x: x.decode(\"utf-8\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tests \n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef57cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./train\n",
    "!mkdir ./test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(dataset, row, path):\n",
    "    #Grab the image data in row-major form\n",
    "    img = dataset[b'data'][row.row]\n",
    "    \n",
    "    # Consolidated stacking/reshaping from earlier\n",
    "    target = np.dstack(img.reshape(3,32,32))\n",
    "    \n",
    "    # Save the image\n",
    "    plt.imsave(path+row['filenames'], target)\n",
    "    \n",
    "    # Return any signal data you want for debugging\n",
    "    return 0\n",
    "\n",
    "## TODO: save ALL images using the save_images function\n",
    "for idx, row in df_train.iterrows():\n",
    "    save_images(dataset_train, row, './train/')\n",
    "    \n",
    "for idx, row in df_test.iterrows():\n",
    "    save_images(dataset_test, row, './test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4065027",
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m pip install tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # 2 classes: bicycle and motorcycle\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators for train and test sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    './test',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,  # Adjust based on the dataset size\n",
    "    epochs=28,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('./image_classification_model.h5')\n",
    "\n",
    "print(\"Model trained and saved locally.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the function to create metadata .lst files\n",
    "def to_metadata_file(df, prefix):\n",
    "    # Set the s3_path (or local file path) to the filenames\n",
    "    df[\"s3_path\"] = df[\"filenames\"]\n",
    "    \n",
    "    # Assign labels: 0 for bicycles (label 8), 1 for motorcycles (label 48)\n",
    "    df[\"labels\"] = df[\"labels\"].apply(lambda x: 0 if x == 8 else 1)\n",
    "    \n",
    "    # Save the dataframe to a .lst file\n",
    "    df[[\"row\", \"labels\", \"s3_path\"]].to_csv(\n",
    "        f\"{prefix}.lst\", sep=\"\\t\", index=False, header=False\n",
    "    )\n",
    "    print(f\"{prefix}.lst file created successfully.\")\n",
    "\n",
    "# Apply the function to the train and test datasets\n",
    "to_metadata_file(df_train.copy(), \"train\")\n",
    "to_metadata_file(df_test.copy(), \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac058c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50846d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db89c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
